{"title":"ruby:魔幻语言的魅力","zzzContent":"某一阵子以前，我周末都在捣鼓一个东西，这个东西是一个站内Spider,基本就是用wget 将某站点的内容抓下来,分析链接，取回正文页，然后对正文页经过分析，抓取它的正文内容，说白了其实就是一个采集程序，只是我组合了wget,diff,tidy这三个gnu工具,尽量不用程序而已。最后完工后没花多少代码，却工作得非常好。\n于是信心受到鼓舞，要用ruby写一个spider.正好原来尝试过用ruby 分词，索引，搜索，这下可以组合起来。写完后，整个spider1000来行代码:\n<coolcode>\n  123 lib/ConfParser.rb\n  129 lib/DataWasher.rb\n   29 lib/Downloader.rb\n   10 lib/HtmlTidy.rb\n   47 lib/Logger.rb\n 1126 lib/mysql.rb\n   53 lib/OptParser.rb\n   77 lib/RobotRules.rb\n   38 lib/SiteLocker.rb\n  325 lib/spider_instance.rb\n   89 lib/Spider.rb\n   46 lib/Storage.rb\n   63 lib/ThreadPool.rb\n   52 lib/UrlDispatcher.rb\n   88 lib/UrlGrabber.rb\n   40 lib/UrlScorer.rb\n 2335 总计\n</coolcode>\n(注意mysql.rb 和spider_instance.rb是跟项目无关的，另外bin目录还有一个文件) ,\n结果网上搜到一个spider项目，代码量更惊人的少,300行!\n拜读了一下，人家的代码果然是够ruby,太酷了,我一开始都搞晕了:\n<coolcode>\n        urls.map do |a_url|\n          [a_url, (URI.parse(a_url) rescue nil)]\n        end.select do |a_url, parsed_url|\n          allowable_url?(a_url, parsed_url)\n        end.each do |a_url, parsed_url|\n          @setup.call(a_url) unless @setup.nil?\n          get_page(parsed_url) do |response|\n            do_callbacks(a_url, response, prior_url)\n            #tmp_n_u[a_url] = generate_next_urls(a_url, response)\n            #@next_urls.push tmp_n_u\n            generate_next_urls(a_url, response).each do |a_next_url|\n              @next_urls.push a_url => a_next_url\n            end\n            #exit if interrupted\n          end\n          @teardown.call(a_url) unless @teardown.nil?\n          exit if interrupted\n        end\n</coolcode>\n这一段代码外面还有好几层do ..end。还好还很直白。扫了一下整个工程的代码，几乎大半以上的方法都接收一个代码块参数，也就是说，几乎所有的方法要运行的内容都是未知的。有点php里面的所有代码都是eval来执行的那意思。\n就是不知道代码写成这样了效率会怎么样。我自己的spider跑一天了也只是报告同时打开的文件句柄太多，内存和cpu占用还好。改天测试测试。","postDate":"2008-08-25 00:12:50","postId":"686","type":"post","status":"draft"}